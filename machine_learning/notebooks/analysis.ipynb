"""
📓 Análise de Machine Learning - Notebook em Python
Sistema de Manutenção Preditiva - Hermes Reply Challenge

Este arquivo substitui o Jupyter Notebook e contém toda a análise de ML
"""

# ============================================================================
# 📚 IMPORTAÇÕES E CONFIGURAÇÕES
# ============================================================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

print("🚀 SISTEMA DE MANUTENÇÃO PREDITIVA - HERMES REPLY")
print("="*60)
print("📓 Análise completa de Machine Learning")
print("🤖 Algoritmo: Random Forest Classifier")
print("📊 Objetivo: Classificação de status de equipamentos")
print("="*60)

# ============================================================================
# 📊 CARREGAMENTO E EXPLORAÇÃO DOS DADOS
# ============================================================================

def load_and_explore_data():
    """Carrega e explora o dataset"""
    print("\n📊 CARREGANDO DADOS...")
    
    # Carregando dados
    df = pd.read_csv('../data/sensor_data_sample.csv')
    
    print(f"✅ Dataset carregado: {len(df)} registros")
    print(f"📈 Colunas: {list(df.columns)}")
    print(f"🔍 Shape: {df.shape}")
    
    # Informações gerais
    print(f"\n📋 INFORMAÇÕES GERAIS:")
    print(f"• Total de registros: {len(df):,}")
    print(f"• Sensores únicos: {df['sensor_id'].nunique()}")
    print(f"• Equipamentos únicos: {df['equipment_id'].nunique()}")
    print(f"• Período: {df['timestamp'].min()} até {df['timestamp'].max()}")
    
    # Distribuição dos status
    print(f"\n📊 DISTRIBUIÇÃO DOS STATUS:")
    status_counts = df['status'].value_counts()
    for status, count in status_counts.items():
        percentage = (count / len(df)) * 100
        print(f"• {status}: {count:,} ({percentage:.1f}%)")
    
    # Estatísticas dos sensores
    numeric_cols = ['temperature', 'humidity', 'pressure', 'vibration', 'current']
    print(f"\n🌡️ ESTATÍSTICAS DOS SENSORES:")
    print(df[numeric_cols].describe().round(2))
    
    return df

# ============================================================================
# 🔧 PRÉ-PROCESSAMENTO
# ============================================================================

def preprocess_data(df):
    """Prepara os dados para ML"""
    print(f"\n🔧 PRÉ-PROCESSAMENTO DOS DADOS...")
    
    # Features e target
    feature_names = ['temperature', 'humidity', 'pressure', 'vibration', 'current']
    X = df[feature_names]
    y = df['status']
    
    # Codificando target
    label_encoder = LabelEncoder()
    y_encoded = label_encoder.fit_transform(y)
    
    print(f"• Features: {feature_names}")
    print(f"• Classes: {list(label_encoder.classes_)}")
    print(f"• Codificação: {dict(zip(label_encoder.classes_, range(len(label_encoder.classes_))))}")
    
    # Train-test split
    X_train, X_test, y_train, y_test = train_test_split(
        X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
    )
    
    print(f"\n📊 DIVISÃO DOS DADOS:")
    print(f"• Treino: {len(X_train)} amostras ({len(X_train)/len(X)*100:.1f}%)")
    print(f"• Teste: {len(X_test)} amostras ({len(X_test)/len(X)*100:.1f}%)")
    
    # Normalização
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    print(f"✅ Dados normalizados com StandardScaler")
    
    return X_train_scaled, X_test_scaled, y_train, y_test, label_encoder, feature_names

# ============================================================================
# 🤖 TREINAMENTO DO MODELO
# ============================================================================

def train_model(X_train_scaled, y_train):
    """Treina o modelo Random Forest"""
    print(f"\n🤖 TREINANDO MODELO RANDOM FOREST...")
    
    model = RandomForestClassifier(
        n_estimators=100,
        max_depth=10,
        min_samples_split=5,
        min_samples_leaf=2,
        random_state=42
    )
    
    # Treinamento
    model.fit(X_train_scaled, y_train)
    
    print(f"✅ Modelo treinado com sucesso!")
    print(f"🎯 Parâmetros: n_estimators={model.n_estimators}, max_depth={model.max_depth}")
    
    return model

# ============================================================================
# 📊 AVALIAÇÃO DO MODELO
# ============================================================================

def evaluate_model(model, X_test_scaled, y_test, label_encoder):
    """Avalia a performance do modelo"""
    print(f"\n📊 AVALIAÇÃO DO MODELO")
    print("="*50)
    
    # Predições
    y_pred = model.predict(X_test_scaled)
    
    # Acurácia
    accuracy = accuracy_score(y_test, y_pred)
    print(f"🎯 Acurácia Geral: {accuracy:.3f} ({accuracy*100:.1f}%)")
    
    # Relatório detalhado
    target_names = label_encoder.classes_
    report = classification_report(y_test, y_pred, target_names=target_names, output_dict=True)
    
    print(f"\n📋 RELATÓRIO POR CLASSE:")
    for class_name in target_names:
        metrics = report[class_name]
        print(f"\n• {class_name}:")
        print(f"  - Precisão: {metrics['precision']:.3f} ({metrics['precision']*100:.1f}%)")
        print(f"  - Recall: {metrics['recall']:.3f} ({metrics['recall']*100:.1f}%)")
        print(f"  - F1-Score: {metrics['f1-score']:.3f}")
        print(f"  - Suporte: {int(metrics['support'])} amostras")
    
    # Matriz de confusão
    cm = confusion_matrix(y_test, y_pred)
    print(f"\n📊 MATRIZ DE CONFUSÃO:")
    print("    ", "  ".join(f"{name:>8}" for name in target_names))
    for i, row in enumerate(cm):
        print(f"{target_names[i]:>8}", "  ".join(f"{val:>8}" for val in row))
    
    return accuracy, report, y_pred

# ============================================================================
# 🔍 IMPORTÂNCIA DAS FEATURES
# ============================================================================

def analyze_feature_importance(model, feature_names):
    """Analisa a importância das features"""
    print(f"\n🔍 IMPORTÂNCIA DAS FEATURES")
    print("="*40)
    
    importances = model.feature_importances_
    indices = np.argsort(importances)[::-1]
    
    print(f"📊 Ranking de Importância:")
    for i, idx in enumerate(indices):
        feature = feature_names[idx]
        importance = importances[idx]
        print(f"{i+1}. {feature}: {importance:.3f} ({importance*100:.1f}%)")
    
    print(f"\n💡 Feature mais importante: {feature_names[indices[0]]} ({importances[indices[0]]*100:.1f}%)")
    
    return importances, indices

# ============================================================================
# 🔮 EXEMPLOS DE PREDIÇÕES
# ============================================================================

def generate_predictions_examples(model, X_test, X_test_scaled, y_test, label_encoder):
    """Gera exemplos de predições"""
    print(f"\n🔮 EXEMPLOS DE PREDIÇÕES EM TEMPO REAL")
    print("="*60)
    
    # Selecionando 3 amostras
    sample_indices = np.random.choice(len(X_test), 3, replace=False)
    
    for i, idx in enumerate(sample_indices):
        real_features = X_test.iloc[idx]
        real_status = label_encoder.classes_[y_test[idx]]
        
        # Predição
        pred_features = X_test_scaled[idx].reshape(1, -1)
        pred_status_encoded = model.predict(pred_features)[0]
        pred_status = label_encoder.classes_[pred_status_encoded]
        
        # Probabilidades
        probabilities = model.predict_proba(pred_features)[0]
        confidence = max(probabilities)
        
        print(f"\n🔧 Equipamento {i+1}:")
        print(f"📊 Sensores: T={real_features['temperature']:.1f}°C, "
              f"H={real_features['humidity']:.1f}%, "
              f"P={real_features['pressure']:.3f}bar, "
              f"V={real_features['vibration']:.2f}Hz, "
              f"I={real_features['current']:.1f}A")
        print(f"🎯 Real: {real_status} | Predito: {pred_status} | Confiança: {confidence:.1%}")
        
        if real_status == pred_status:
            print("✅ CORRETO")
        else:
            print("❌ INCORRETO")

# ============================================================================
# 🏆 RESUMO FINAL
# ============================================================================

def final_summary(accuracy, feature_names, indices, importances):
    """Resumo final do projeto"""
    print(f"\n" + "="*60)
    print("🏆 RESUMO FINAL DO PROJETO")
    print("="*60)
    
    print(f"\n🤖 MODELO DESENVOLVIDO:")
    print(f"• Algoritmo: Random Forest Classifier")
    print(f"• Acurácia: {accuracy:.1%}")
    print(f"• Features: {len(feature_names)} sensores")
    print(f"• Classes: 3 status (NORMAL, ATENÇÃO, CRÍTICO)")
    
    print(f"\n🎯 PROBLEMA RESOLVIDO:")
    print(f"• Classificação automática de status de equipamentos")
    print(f"• Detecção precoce de problemas")
    print(f"• Manutenção preditiva eficiente")
    
    print(f"\n�� FEATURE MAIS IMPORTANTE:")
    print(f"• {feature_names[indices[0]]}: {importances[indices[0]]*100:.1f}%")
    
    print(f"\n✅ PROJETO CONCLUÍDO COM SUCESSO!")
    print(f"🚀 Modelo pronto para implementação industrial!")

# ============================================================================
# 🚀 EXECUÇÃO PRINCIPAL
# ============================================================================

if __name__ == "__main__":
    # Executando todo o pipeline
    df = load_and_explore_data()
    X_train_scaled, X_test_scaled, y_train, y_test, label_encoder, feature_names = preprocess_data(df)
    model = train_model(X_train_scaled, y_train)
    accuracy, report, y_pred = evaluate_model(model, X_test_scaled, y_test, label_encoder)
    importances, indices = analyze_feature_importance(model, feature_names)
    generate_predictions_examples(model, pd.DataFrame(X_test_scaled), X_test_scaled, y_test, label_encoder)
    final_summary(accuracy, feature_names, indices, importances)
